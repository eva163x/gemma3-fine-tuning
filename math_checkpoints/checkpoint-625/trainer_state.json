{
  "best_global_step": 600,
  "best_metric": 1.1507072448730469,
  "best_model_checkpoint": "./math_checkpoints/checkpoint-600",
  "epoch": 1.0,
  "eval_steps": 200,
  "global_step": 625,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.032,
      "grad_norm": 4.815954685211182,
      "learning_rate": 4.848000000000001e-06,
      "loss": 1.5033,
      "step": 20
    },
    {
      "epoch": 0.064,
      "grad_norm": 3.553645610809326,
      "learning_rate": 4.688000000000001e-06,
      "loss": 1.4184,
      "step": 40
    },
    {
      "epoch": 0.096,
      "grad_norm": 2.6895647048950195,
      "learning_rate": 4.5280000000000005e-06,
      "loss": 1.3616,
      "step": 60
    },
    {
      "epoch": 0.128,
      "grad_norm": 1.3594110012054443,
      "learning_rate": 4.368e-06,
      "loss": 1.2838,
      "step": 80
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.2410029172897339,
      "learning_rate": 4.208e-06,
      "loss": 1.2584,
      "step": 100
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.1272814273834229,
      "learning_rate": 4.048e-06,
      "loss": 1.3154,
      "step": 120
    },
    {
      "epoch": 0.224,
      "grad_norm": 1.1773499250411987,
      "learning_rate": 3.888e-06,
      "loss": 1.1913,
      "step": 140
    },
    {
      "epoch": 0.256,
      "grad_norm": 1.2521111965179443,
      "learning_rate": 3.7280000000000006e-06,
      "loss": 1.2756,
      "step": 160
    },
    {
      "epoch": 0.288,
      "grad_norm": 1.0173425674438477,
      "learning_rate": 3.5680000000000004e-06,
      "loss": 1.181,
      "step": 180
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0322142839431763,
      "learning_rate": 3.4080000000000002e-06,
      "loss": 1.1325,
      "step": 200
    },
    {
      "epoch": 0.32,
      "eval_loss": 1.2117745876312256,
      "eval_runtime": 26.3994,
      "eval_samples_per_second": 47.35,
      "eval_steps_per_second": 11.856,
      "step": 200
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.1726090908050537,
      "learning_rate": 3.248e-06,
      "loss": 1.1634,
      "step": 220
    },
    {
      "epoch": 0.384,
      "grad_norm": 1.0346825122833252,
      "learning_rate": 3.0880000000000003e-06,
      "loss": 1.215,
      "step": 240
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.2050892114639282,
      "learning_rate": 2.928e-06,
      "loss": 1.1811,
      "step": 260
    },
    {
      "epoch": 0.448,
      "grad_norm": 1.0735514163970947,
      "learning_rate": 2.768e-06,
      "loss": 1.1326,
      "step": 280
    },
    {
      "epoch": 0.48,
      "grad_norm": 3.176424026489258,
      "learning_rate": 2.608e-06,
      "loss": 1.1092,
      "step": 300
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.1512666940689087,
      "learning_rate": 2.448e-06,
      "loss": 1.1524,
      "step": 320
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.2924457788467407,
      "learning_rate": 2.2880000000000004e-06,
      "loss": 1.1914,
      "step": 340
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.9606590867042542,
      "learning_rate": 2.128e-06,
      "loss": 1.1928,
      "step": 360
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.8965215682983398,
      "learning_rate": 1.968e-06,
      "loss": 1.1227,
      "step": 380
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0787891149520874,
      "learning_rate": 1.808e-06,
      "loss": 1.1263,
      "step": 400
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.1623414754867554,
      "eval_runtime": 26.5848,
      "eval_samples_per_second": 47.019,
      "eval_steps_per_second": 11.774,
      "step": 400
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.1892964839935303,
      "learning_rate": 1.6480000000000001e-06,
      "loss": 1.0785,
      "step": 420
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.8599135279655457,
      "learning_rate": 1.488e-06,
      "loss": 1.1207,
      "step": 440
    },
    {
      "epoch": 0.736,
      "grad_norm": 1.1651982069015503,
      "learning_rate": 1.328e-06,
      "loss": 1.1768,
      "step": 460
    },
    {
      "epoch": 0.768,
      "grad_norm": 1.0399601459503174,
      "learning_rate": 1.168e-06,
      "loss": 1.1606,
      "step": 480
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.9745200276374817,
      "learning_rate": 1.0080000000000001e-06,
      "loss": 1.0897,
      "step": 500
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.1826424598693848,
      "learning_rate": 8.480000000000001e-07,
      "loss": 1.1291,
      "step": 520
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.7293598055839539,
      "learning_rate": 6.88e-07,
      "loss": 1.0841,
      "step": 540
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.954276978969574,
      "learning_rate": 5.280000000000001e-07,
      "loss": 1.1471,
      "step": 560
    },
    {
      "epoch": 0.928,
      "grad_norm": 1.1193618774414062,
      "learning_rate": 3.68e-07,
      "loss": 1.1254,
      "step": 580
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.9303337931632996,
      "learning_rate": 2.08e-07,
      "loss": 1.1345,
      "step": 600
    },
    {
      "epoch": 0.96,
      "eval_loss": 1.1507072448730469,
      "eval_runtime": 26.7325,
      "eval_samples_per_second": 46.76,
      "eval_steps_per_second": 11.709,
      "step": 600
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.8795211911201477,
      "learning_rate": 4.8e-08,
      "loss": 1.1109,
      "step": 620
    }
  ],
  "logging_steps": 20,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3654820661818368.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
